The company is grappling with a challenge of managing the mess associated with bureaucratic-paper-party of truck transit across national borders. Truck drivers are snapping gigabytes worth of pics on their smartphones right at the border and are sending it to the office workers. Evidently, there's an a demand for the automation of the process that involves cataloging both the physical documents and the data embedded within the aforementioned files into the organizational database.

This is where my involvement takes center stage. My endeavor revolves around implementing a systematic document categorization mechanism and also leveraging OCR to transform image-based content into text. Technically speaking, I build a model to classify documents and OCR mechanism to extract text from it (which later on will be structured, relevant parts like doc number extracted, and pushed to db).

### Key takaways, lessons learned and issues faced:

1. **ü´ß Filtering out unrelated documents or outlier detection techniques and failures**. With five distinct document classes, we anticipated that production will bring a 6th class - bunch of irrelevant documents hiding among the 5 classes of documents we cared about. We needed a way to filter them out. What if we swapped the softmax activation in the final layer for a sigmoid, and couple with a threshold mechanism to weed out these other documents? Intuitively, the model should output low scores to unfamiliar documents, right? *Right..? Wrong!* The reality was a total departure from the expectations (*I'll save the nitty-gritty explanation for another occasion*). Experimenting with an encoder-decoder setup for outlier identification yielded suboptimal results. Ultimately, simple solution prevailed as I introduced an additional class explicitly designated for other documents. How do we get the training data from the other class? Use a bunch of different public document datasets and construct your own *other* class. Though lacking elegance, this simple solution proved to be the most effective.

2. **üíß Data leakage, document-level contamination**. Uff, this one is quite tought and was hard to spot. Picture this: you are building up a classifier that looks at a page and outputs its class. The initial dataset is a stack of PDFs. How do you construct train, test and validation data sets? Initial thought: loop through the PDFs, extract each page as an image, and then randomly shuffle all of it into the three data sets, right? Hold your horses. We're setting up ourselves for a the data leakage failure. Why? Because we don't want pages from the same document to end up in different data sets. Every page from a single PDF needs to sit together in the same data set.

3. **üë®‚Äçüî¨ Look at the data, even post proccessed images, to grasp how the model works**. Take a casual peek at the reshaped and randomly rotated images that are fed to the model ‚Äì and then it hits you, even for us humans, it's such a hard task. The document's appearance contain only a small subset of the total signal. How about we suplement the looks of it with the text that is inside the page? This trick sent the model's performance soaring sky-high. Since the documents span a myriad of languages [this universal sentence encoder](https://tfhub.dev/google/universal-sentence-encoder-multilingual/3) worked marvelously and got things done.

4. **üóø Stand on the sholders of the giants**. When faced with tasks that are practically household names, i.e. OCR - summon the heavyweights, the giants of the tech, and use their power. I used [google OCR service](https://cloud.google.com/vision/docs/ocr). Unless you're doing it just for the sheer joy of learning or the thrill of exploration.

5. **ü§ñ Deploying and serving image data to the server**. How do you serve you images to the model over a post request? Yes you are right, you serve them in string64, not json with arrays of pixel values. Else you're setting the stage for a payload-size catastrophe. How do you couple this with tensorflow/serving? You [wrap a model around another model](https://github.com/tensorflow/serving/issues/1869#issuecomment-873455598) solely designed to preprocess the string64 input.

So far only a demo solution is ready, I wonder and anticipate the other callanges that the production env will bring.
